{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "b6NfEOe-RBBa",
        "4MK_XYjbZpgm",
        "-828AjatdWyH",
        "nrOs2dDyRDHP",
        "X-vtPNN7ks9P",
        "9QfLjLDPl2pn",
        "3raej91brI5i",
        "ClSucYMordlq",
        "deBESccxmM1v",
        "qjTzwHMamZRi",
        "cJGW7dnPmgUw",
        "C_Q6nYfZmVAi",
        "YU_KxSgOmnaz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import"
      ],
      "metadata": {
        "id": "Bwe69GeoQ-RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "LLr3Pf0bsbYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VftoROaZLwd-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import calendar\n",
        "from datetime import datetime\n",
        "import pyarrow.parquet as pq\n",
        "pd.set_option('display.max_columns', None)\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import original dataset\n",
        "df = pd.read_parquet('trots_2013-2022.parquet') # Update with correct file path\n",
        "\n",
        "# Import new data\n",
        "newdf = pd.read_parquet('newdata.parquet') # Update with correctl file path & name\n",
        "# or\n",
        "#newdf = pd.read_csv('newdata.csv')\n",
        "\n",
        "df[\"Set\"] = \"train\"\n",
        "newdf[\"Set\"] = \"test\""
      ],
      "metadata": {
        "id": "t57_YDPYROnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging the new data with the original dataset\n",
        "df = pd.concat([df,newdf])"
      ],
      "metadata": {
        "id": "1W0c4r6jX4hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data cleaning"
      ],
      "metadata": {
        "id": "b6NfEOe-RBBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning\n",
        "\n",
        "def data_cleaning(df):\n",
        "    '''\n",
        "    This function takes in the dataframe and performs data cleaning\n",
        "    '''\n",
        "\n",
        "    ### Data cleaning ###\n",
        "\n",
        "    # Update datatypes\n",
        "    # ID columns to object datatype\n",
        "    for column in [\"RaceID\", \"TrainerID\", \"JockeyID\", \"HorseID\", \"DamID\", \"SireID\", \"TrackID\"]:\n",
        "      df[column] = df[column].astype('object')\n",
        "\n",
        "    # Date columns to datetime\n",
        "    df[\"RaceStartTime\"] = pd.to_datetime(df[\"RaceStartTime\"])\n",
        "    df[\"FoalingDate\"] = pd.to_datetime(df[\"FoalingDate\"])\n",
        "\n",
        "    # Convert 'Saddlecloth' & 'WeightCarried' to integers\n",
        "    df[\"Saddlecloth\"] = df[\"Saddlecloth\"].astype(int)\n",
        "    df[\"WeightCarried\"] = df[\"WeightCarried\"].astype(int)\n",
        "\n",
        "    # Updating and cleaning values\n",
        "    racing_subtype_map = {'T ': 'Attele', 'T':'Attele', 'TM': 'Mounted'}\n",
        "    sex_restriction_map = {'M': 'Mare', 'F': 'Filly', 'C&G': 'Colts&Geldings', '': 'None'}\n",
        "    df.replace({'RacingSubType': racing_subtype_map, 'SexRestriction': sex_restriction_map}, inplace=True)\n",
        "    # Handle Age Restriction\n",
        "    age_restriction_mapping(df)\n",
        "\n",
        "    # Missing values\n",
        "    df = df.replace({\n",
        "        \"RaceGroup\": {'  ': 'Other'},\n",
        "        \"CourseIndicator\": {' ': np.nan},\n",
        "        \"Barrier\": {0: np.nan},\n",
        "        \"HandicapType\": {\"\": \"None\"},\n",
        "        \"HandicapDistance\": {-25: 25, -50: 50, 75: 50}, # unifying values\n",
        "        \"RaceOverallTime\": {0: np.nan},\n",
        "        \"NoFrontCover\": {-9: np.nan},\n",
        "        \"WideOffRail\": {-9: np.nan},\n",
        "        \"BeatenMargin\": {999: np.nan}\n",
        "    }).astype({\n",
        "        \"HandicapDistance\": int\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def age_restriction_mapping(df):\n",
        "  ''' Cleans the age restriction variable '''\n",
        "  max_age_map = {\n",
        "      '6yo': 6, '6-9yo': 9, '7yo': 7, '4yo': 4, '3yo': 3, '5yo': 5, '7&8yo': 8, '': 16, '6-8yo': 8, '4&5yo': 5, '7-10yo': 10, '6-10yo': 10, '6&7yo': 7, '5-10yo': 10,\n",
        "      '5&6yo': 6, '5-7yo': 7, '2yo': 2, '5-8yo': 8, '5-9yo': 9, '7-9yo': 9, '8-10yo': 10, '4-6yo': 6, '4-7yo': 7,'4-10yo': 10, '6yo+': 16, '4yo+': 16, '4-8yo': 8,\n",
        "      '8&9yo': 9, '7yo+': 16, '4-9yo': 9,'3-5yo': 5, '5yo+': 16, '3yo+': 16, '3-10yo': 10, '8yo+': 16, '8yo': 8, 'Pour 9': 9,'9&10yo': 10\n",
        "    }\n",
        "\n",
        "  min_age_map = {\n",
        "      '6yo': 0, '6-9yo': 6, '7yo': 0, '4yo': 0, '3yo': 0, '5yo': 0, '7&8yo': 7, '': 0, '6-8yo': 6, '4&5yo': 4, '7-10yo': 7, '6-10yo': 6, '6&7yo': 6, '5-10yo': 5,\n",
        "      '5&6yo': 5, '5-7yo': 5, '2yo': 0, '5-8yo': 5, '5-9yo': 5, '7-9yo': 7, '8-10yo': 8, '4-6yo': 4, '4-7yo': 4,'4-10yo': 4, '6yo+': 6, '4yo+': 4, '4-8yo': 4, '8&9yo': 8,\n",
        "      '7yo+': 7, '4-9yo': 4,'3-5yo': 3, '5yo+': 5, '3yo+': 3, '3-10yo': 3, '8yo+': 8, '8yo': 0, 'Pour 9': 0,'9&10yo': 9\n",
        "    }\n",
        "\n",
        "  df[\"max_age\"] = df[\"AgeRestriction\"].replace(max_age_map)\n",
        "  df[\"min_age\"] = df[\"AgeRestriction\"].replace(min_age_map)\n",
        "  return df"
      ],
      "metadata": {
        "id": "MLwnlOCVRCib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the function\n",
        "df = data_cleaning(df)"
      ],
      "metadata": {
        "id": "JfVgjtnHaJTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Feature Engineering"
      ],
      "metadata": {
        "id": "4MK_XYjbZpgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Initial feature engineering"
      ],
      "metadata": {
        "id": "sztcKkHPdR9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining functions for basic feature engineering\n",
        "\n",
        "def get_season(df):\n",
        "  '''\n",
        "  Get season from RaceStartTime\n",
        "  '''\n",
        "  df['Month'] = pd.DatetimeIndex(df['RaceStartTime']).month\n",
        "  season_map = {12: \"Winter\", 1: \"Winter\", 2: \"Winter\", 3: \"Spring\", 4: \"Spring\", 5: \"Spring\", 6: \"Summer\", 7: \"Summer\", 8: \"Summer\", 9: \"Fall\", 10: \"Fall\", 11: \"Fall\"}\n",
        "  df[\"Season\"] = df['Month'].map(season_map)\n",
        "\n",
        "\n",
        "def assign_race_outcome(df):\n",
        "    '''\n",
        "    Determines winner for each race based on highest Prizemoney.\n",
        "    Determines whether the horse started the race and finished the race, and whether the horse placed 1-7.\n",
        "    Corrects finish position for horses who did not finish the race or were disqualified\n",
        "    '''\n",
        "    idx_winners = df.groupby(\"RaceID\")[\"Prizemoney\"].idxmax()\n",
        "    df[\"WIN\"] = False\n",
        "    df.loc[idx_winners, \"WIN\"] = True\n",
        "\n",
        "    # List of finish position codes indicating non-completion\n",
        "    finishpositionletters = [\"BS\", \"UN\", \"UR\", \"WC\", \"FL\", \"NP\", \"DQ\", \"PU\"]\n",
        "\n",
        "    # Assign Started_race and Finished_race status\n",
        "    df[\"Started_race\"] = df[\"FinishPosition\"].str.strip() != \"NP\"\n",
        "    df[\"Finished_race\"] = ~df[\"FinishPosition\"].str.strip().isin(finishpositionletters)\n",
        "\n",
        "    # Fix FinishPosition\n",
        "    df[\"FinishPosition_2\"] = df.apply(lambda x: x[\"Nb_Participants\"] if (x[\"Started_race\"] == False) or (x[\"Finished_race\"] == False) or (x[\"Disqualified\"] == True) else x[\"FinishPosition\"], axis=1).astype(int)\n",
        "\n",
        "    # Create a 'Placed' variable for horses that finished 1-7 and weren't disqualified\n",
        "    df[\"Placed\"] = (df[\"FinishPosition_2\"] <= 7) & (~df.get(\"Disqualified\", False))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_age_position(df):\n",
        "  '''\n",
        "  Creates a new column where the age of the horse is considered in relation to the age of the youngest and oldest horse within that race.\n",
        "  A value of 0 means the horse's age is the lowest within the race. A value of 1 means the horse's age is the highest within the race.\n",
        "  '''\n",
        "  # For each race, get the youngest horse's age and the oldest horse's age\n",
        "  race_min_age = df.groupby('RaceID')['HorseAge'].transform('min')\n",
        "  race_max_age = df.groupby('RaceID')['HorseAge'].transform('max')\n",
        "\n",
        "  # Compute relative ages\n",
        "  df['Relative_age'] = np.where(race_max_age == race_min_age, 0.5, (df['HorseAge'] - race_min_age) / (race_max_age - race_min_age))"
      ],
      "metadata": {
        "id": "mKj4mYBxb-tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Season variable\n",
        "get_season(df)\n",
        "\n",
        "# Number of participants variable\n",
        "nb_participants = df.groupby(\"RaceID\")[\"HorseID\"].nunique().to_frame('Nb_Participants')\n",
        "df = df.merge(nb_participants, on=\"RaceID\")\n",
        "\n",
        "# Binary 'WIN', 'Started_race', 'Finished_race' and 'Placed' variables, + adjustments to Finish Positions\n",
        "assign_race_outcome(df)\n",
        "\n",
        "# Rearranging columns & dropping redundant ones\n",
        "df = df[['Set','RaceID', 'TrainerID', 'JockeyID', 'HorseID', 'HorseAge', 'Gender', 'DamID', 'SireID', 'FoalingCountry', 'FoalingDate', 'FrontShoes','HindShoes', 'RaceGroup',\n",
        "         'RacingSubType', 'ClassRestriction','min_age','max_age','SexRestriction','RacePrizemoney', 'Nb_Participants', 'TrackID','Distance', 'Surface', 'WetnessScale',\n",
        "         'RaceStartTime', 'Season','StartType', 'StartingLine', 'Barrier', 'Saddlecloth','WeightCarried', 'HandicapType', 'HandicapDistance','FinishPosition',\n",
        "         'FinishPosition_2','Prizemoney','WIN','BeatenMargin','Started_race', 'Finished_race', 'Placed', 'Disqualified', 'RaceOverallTime',\n",
        "         ]]\n",
        "\n",
        "# Relative age variable\n",
        "get_age_position(df)"
      ],
      "metadata": {
        "id": "u02bIhJdbQ-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Feature engineering with historical data"
      ],
      "metadata": {
        "id": "-828AjatdWyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating 'FinishPosition_3' where non-finishers are assigned last place + 1 to differentiate from those actually finishing the race\n",
        "\n",
        "df[\"FinishPosition_3\"] = df[\"FinishPosition\"]\n",
        "finishpositionletters = [\"BS \", \"UN \", \"UR \", \"WC \", \"FL \", \"NP \", \"DQ \", \"PU \"]\n",
        "\n",
        "for x in finishpositionletters:\n",
        "    mask = df['FinishPosition'] == x\n",
        "    df.loc[mask, 'FinishPosition_3'] = (df.loc[mask, 'Nb_Participants'] + 1).astype(int)\n",
        "\n",
        "df['FinishPosition_3'] = pd.to_numeric(df['FinishPosition_3'], errors='coerce')\n",
        "df['FinishPosition_3'] = np.where(df['Disqualified'], df['Nb_Participants']+1, df['FinishPosition_3'])"
      ],
      "metadata": {
        "id": "NO1soIeUctIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Score for the race, based on finish position (post-race variable)\n",
        "df['Score'] = 1 / df['FinishPosition_3']\n",
        "\n",
        "# Scaled score at the RaceID level (post-race variable)\n",
        "df['Min_Score'] = df.groupby('RaceID')['Score'].transform('min')\n",
        "df['Max_Score'] = df.groupby('RaceID')['Score'].transform('max')\n",
        "df['Score_norm'] = (df['Score'] - df['Min_Score']) / (df['Max_Score'] - df['Min_Score'])\n",
        "df = df.drop(columns=[\"Min_Score\",\"Max_Score\"])"
      ],
      "metadata": {
        "id": "RpPziqoudpTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Obtaining Cumulative Past Performance variables for Horses, Jockeys and Trainers\n",
        "\n",
        "entities = [\"horse\", \"jockey\", \"trainer\"]\n",
        "idcols = [\"HorseID\",\"JockeyID\",\"TrainerID\"]\n",
        "prefixes = [\"horse_\",\"jockey_\",\"trainer_\"]\n",
        "\n",
        "for entity, idcol, prefix in zip(entities, idcols, prefixes):\n",
        "  entity_df = df[['HorseID', 'RaceID', 'TrainerID', 'JockeyID', 'RaceStartTime', 'WIN', 'Placed', 'Prizemoney', 'FinishPosition_3', 'Score_norm']]\n",
        "  entity_df = entity_df.sort_values([idcol, 'RaceStartTime'])\n",
        "  entity_df['Nb_Participations'] = entity_df.groupby(idcol).cumcount() # Cumulative count of participations\n",
        "  entity_df['Nb_of_Wins'] = entity_df.groupby(idcol)['WIN'].cumsum().groupby(entity_df[idcol]).shift(1) # Cumulative total wins\n",
        "  entity_df['Winrate'] = entity_df['Nb_of_Wins'] / entity_df['Nb_Participations'] # cumulative rate of wins\n",
        "  entity_df['Nb_of_times_Placed'] = entity_df.groupby(idcol)['Placed'].cumsum().groupby(entity_df[idcol]).shift(1) # Cumulative count of finishing a race in the top 7\n",
        "  entity_df['Total_Prizemoney'] = entity_df.groupby(idcol)['Prizemoney'].cumsum().groupby(entity_df[idcol]).shift(1) # Cumulative total amount $ won\n",
        "  entity_df['Cumul_Score'] = entity_df.groupby(idcol)['Score_norm'].cumsum().groupby(entity_df[idcol]).shift(1) # Sum of scores from past races\n",
        "  entity_df['AvgScore_All'] = entity_df.groupby(idcol)['Score_norm'].transform(lambda x: x.expanding().mean().groupby(entity_df[idcol]).shift(1)) # Cumulative Avg_Score\n",
        "  entity_df['AvgScore_Last5'] = entity_df.groupby(idcol)['Score_norm'].transform(lambda x: x.rolling(window=5, min_periods=1).mean().groupby(entity_df[idcol]).shift(1)) # Cumulative average score for the last 5 races\n",
        "\n",
        "  entity_df = entity_df[[\"HorseID\",\"RaceID\",\"JockeyID\",\"TrainerID\",\"Nb_Participations\",\"Nb_of_Wins\",\"Winrate\",\"Nb_of_times_Placed\",\"Total_Prizemoney\",\"AvgScore_All\",\"AvgScore_Last5\",\"Cumul_Score\"]]\n",
        "  entity_df = entity_df.rename(columns={\"Nb_Participations\": prefix + \"Nb_Participations\",\n",
        "                                \"Nb_of_Wins\": prefix + \"NbWins\",\n",
        "                                \"Winrate\": prefix + \"winrate\",\n",
        "                                \"Nb_of_times_Placed\": prefix + \"nb_timesplaced\",\n",
        "                                \"Total_Prizemoney\": prefix + \"totalprizemoney\",\n",
        "                                \"AvgScore_All\": prefix + \"AvgScore\",\n",
        "                                \"AvgScore_Last5\": prefix + \"AvgScore_Last5\",\n",
        "                                \"Cumul_Score\": prefix + \"CumulScore\",\n",
        "                                })\n",
        "\n",
        "  df = df.merge(entity_df, on=[\"HorseID\",\"JockeyID\",\"TrainerID\",\"RaceID\"])\n",
        "\n",
        "# Replacing \"inf\" values with NaN\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "rpGRYaoHaPPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Obtaining an indicator of which surface type a horse tends to perform best on\n",
        "\n",
        "df = df.sort_values([\"HorseID\", 'RaceStartTime'])\n",
        "\n",
        "# a. Obtaining separate performance scores for each surface type\n",
        "surfacetypes = [\"S\",\"C\",\"T\"]\n",
        "for surface in surfacetypes:\n",
        "  label = str(\"CumulativeScore_\" + surface)\n",
        "  # Dividing Scaled Scores by the Number of Races for each surface type\n",
        "  df[label] = (df.loc[df[\"Surface\"]==surface].groupby(\"HorseID\")['Score_norm'].cumsum().groupby(df[\"HorseID\"]).shift(1)) / (df.loc[df[\"Surface\"]==surface].groupby(\"HorseID\").cumcount())\n",
        "  # Forward fill\n",
        "  df[label] = df[label].ffill()\n",
        "\n",
        "# b. Storing the surface with the highest performance score in a new column\n",
        "colslist = [\"CumulativeScore_S\",\"CumulativeScore_C\",\"CumulativeScore_T\"]\n",
        "df['highestscore_surface'] = df[colslist].idxmax(axis=1)\n",
        "df['highestscore_surface'] = df['highestscore_surface'].str[-1]\n",
        "\n",
        "# c. Creating a binary variable indicated whether the race's surface type is the one the horse tends to perform best on\n",
        "df[\"is_preferred_surface\"] = df['highestscore_surface'] == df[\"Surface\"]\n",
        "df[\"is_preferred_surface\"] = df[\"is_preferred_surface\"].astype(int)"
      ],
      "metadata": {
        "id": "LrRJlEdAeThy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Scaled past performance indicators for horses, trainers and jockeys\n",
        "\n",
        "# Average score\n",
        "df['horse_past_perf_score'] = df['horse_CumulScore'] / df['horse_Nb_Participations']\n",
        "df['jockey_past_perf_score'] = df['jockey_CumulScore'] / df['jockey_Nb_Participations']\n",
        "df['trainer_past_perf_score'] = df['trainer_CumulScore'] / df['trainer_Nb_Participations']\n",
        "\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True) # in the eventuality of inf values\n",
        "\n",
        "# Scaling past performance scores at the RaceID level: 1 is the entity with the best score within the race, 0 is the worst within the race.\n",
        "pastperf_metrics = [\"horse_past_perf_score\",\"horse_AvgScore\",\"horse_AvgScore_Last5\",\"jockey_AvgScore\",\"trainer_AvgScore\"]\n",
        "normalized_metrics = [\"horse_past_perf_score_scaled\", \"horse_AvgScore_scaled\", \"horse_AvgScore_Last5_scaled\", \"jockey_AvgScore_scaled\",\"trainer_AvgScore_scaled\"]\n",
        "\n",
        "for metric, normalized in zip(pastperf_metrics,normalized_metrics):\n",
        "  df['Min_Score'] = df.groupby('RaceID')[metric].transform('min')\n",
        "  df['Max_Score'] = df.groupby('RaceID')[metric].transform('max')\n",
        "  df[normalized] = (df[metric] - df['Min_Score']) / (df['Max_Score'] - df['Min_Score'])\n",
        "  df.drop(columns=[\"Min_Score\",\"Max_Score\"])"
      ],
      "metadata": {
        "id": "Jc0sW6EAhJuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Consistency indicators for horse performance, using the standard deviation of the horse's last 5 races\n",
        "\n",
        "#df.sort_values(by=['HorseID', 'RaceStartTime'], ascending=[True, True], inplace=True)\n",
        "#df['horse_consistency_position_unshifted'] = df.groupby('HorseID')['FinishPosition_3'].transform(lambda x: x.rolling(window=5, min_periods=1).std())\n",
        "#df['horse_consistency_position'] = df.groupby('HorseID')['horse_consistency_position_unshifted'].shift(1)\n",
        "\n",
        "# Impute NaN values for horses that have no past races with the global average consistency\n",
        "#mean_consistency = df['horse_consistency_position'].mean()\n",
        "#df['horse_consistency_position'] = df['horse_consistency_position'].fillna(mean_consistency, inplace=True)\n",
        "#df.drop(['horse_consistency_position_unshifted'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "##\n",
        "df.sort_values(by=['HorseID', 'RaceStartTime'], ascending=[True, True], inplace=True)\n",
        "df['horse_consistency_unshifted'] = df.groupby('HorseID')['Score_norm'].transform(lambda x: x.rolling(window=5, min_periods=1).std())\n",
        "df['horse_consistency'] = df.groupby('HorseID')['horse_consistency_unshifted'].shift(1)\n",
        "df.drop(['horse_consistency_unshifted'], axis=1, inplace=True)\n",
        "\n",
        "# Impute NaN values for horses that have no past races with the global average consistency\n",
        "mean_consistency = df['horse_consistency'].mean()\n",
        "df['horse_consistency'].fillna(mean_consistency, inplace=True)"
      ],
      "metadata": {
        "id": "vtU8d4rHh81q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Field Competitiveness\n",
        "\n",
        "df['race_prizemoney_score'] = df['RacePrizemoney'] / df['RacePrizemoney'].max()  # Normalize RacePrizemoney\n",
        "\n",
        "# Calculate the composite past performance score for each horse in a race\n",
        "weights = {\n",
        "    'horse_past_perf_score': 0.3,\n",
        "    'jockey_past_perf_score': 0.4,\n",
        "    'trainer_past_perf_score': 0.2,\n",
        "    'race_prizemoney_score': 0.1\n",
        "}\n",
        "\n",
        "df['composite_past_perf_score'] = (\n",
        "    df['horse_past_perf_score'] * weights['horse_past_perf_score'] +\n",
        "    df['jockey_past_perf_score'] * weights['jockey_past_perf_score'] +\n",
        "    df['trainer_past_perf_score'] * weights['trainer_past_perf_score'] +\n",
        "    df['race_prizemoney_score'] * weights['race_prizemoney_score']\n",
        ")\n",
        "\n",
        "# Calculate field strength using the mean composite score of all horses in the race\n",
        "df['field_strength'] = df.groupby('RaceID')['composite_past_perf_score'].transform('mean')\n",
        "\n",
        "# Standardize the field strength scores\n",
        "scaler = StandardScaler()\n",
        "df['field_strength_scaled'] = scaler.fit_transform(df[['field_strength']])\n",
        "\n",
        "\n",
        "# Unweighted versions of horse/jockey/trainer combined performance scores\n",
        "df['CombinedPerformance_winrate'] = df['horse_winrate'] * df['jockey_winrate'] * df['trainer_winrate']\n",
        "df['CombinedPerformance_avgscore'] = df['horse_AvgScore'] * df['jockey_AvgScore'] * df['trainer_AvgScore']\n",
        "df['CombinedPerformance_avg5score'] = df['horse_AvgScore_Last5'] * df['jockey_AvgScore_Last5'] * df['trainer_AvgScore_Last5']"
      ],
      "metadata": {
        "id": "NIjae8ych9Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Adding indicators based on DamID and SireID (average offspring performance)\n",
        "\n",
        "df.sort_values(['DamID', 'RaceStartTime'], inplace=True)\n",
        "df['Dam_Past_Performance'] = df.groupby('DamID', group_keys = False)['horse_AvgScore_scaled'].apply(lambda x: x.shift(1).expanding().mean())\n",
        "\n",
        "df.sort_values(['SireID', 'RaceStartTime'], inplace=True)\n",
        "df['Sire_Past_Performance'] = df.groupby('SireID', group_keys = False)['horse_AvgScore_scaled'].apply(lambda x: x.shift(1).expanding().mean())"
      ],
      "metadata": {
        "id": "fnXJbfrJh9Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Age & Prize interaction term\n",
        "df['Age_Prize_Interaction'] = df['HorseAge'] * df['RacePrizemoney']"
      ],
      "metadata": {
        "id": "IRlKoo1YjhN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Rest period (number of days since the last race)\n",
        "\n",
        "df.sort_values(by=['HorseID', 'RaceStartTime'], inplace=True)\n",
        "df['RestPeriod'] = df.groupby('HorseID')['RaceStartTime'].diff().dt.days\n",
        "df.loc[df[\"RestPeriod\"] > 50, \"RestPeriod\"] = 50   # Capping values at 50 days (very long rests are not meaningful)"
      ],
      "metadata": {
        "id": "RWRKrkXCjnAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by=[\"RaceStartTime\",\"FinishPosition_3\"])"
      ],
      "metadata": {
        "id": "WjyRxUg_tJMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data pre-processing"
      ],
      "metadata": {
        "id": "nrOs2dDyRDHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoding"
      ],
      "metadata": {
        "id": "X-vtPNN7ks9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Binary variables\n",
        "\n",
        "# Unifying the format of binary/boolean variables\n",
        "df[\"Gender_is_male\"] = df[\"Gender\"].replace({\"F\":0, \"M\":1}).astype(int)\n",
        "df[\"RacingType_mounted\"] = df[\"RacingSubType\"].replace({\"Mounted\":1, \"Attele\":0}).astype(int)\n",
        "df[\"StartType_volte\"] = df[\"StartType\"].replace({\"V\":1, \"M\":0}).astype(int)\n",
        "\n",
        "boolean_cols = ['Started_race','Finished_race', 'Placed', 'Disqualified', 'WIN']\n",
        "for col in boolean_cols:\n",
        "  df[col] = df[col].astype(int)"
      ],
      "metadata": {
        "id": "UEYVxNmDRFKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Minor adjustments\n",
        "df.loc[(df[\"StartType_volte\"]==0) & (df[\"StartingLine\"]==-1) & (df[\"Saddlecloth\"]<=9), \"StartingLine\"] = 1 # Putting them in 1st line if Saddlecloth < 10\n",
        "df.loc[(df[\"StartType_volte\"]==0) & (df[\"StartingLine\"]==-1) & (df[\"Saddlecloth\"]>9), \"StartingLine\"] = 2 # 2nd line if Saddlecloth > 10\n",
        "df.loc[(df[\"StartType_volte\"]==1), \"StartingLine\"] = np.nan # For volte start races, replacing StartingLine = -1 by NaN\n",
        "\n",
        "df.loc[(df[\"RacingType_mounted\"]==0), \"WeightCarried\"] = np.nan # For attele races, replacing WeightCarried = 0 by NaN\n",
        "df.loc[df[\"WeightCarried\"]==0, \"WeightCarried\"] = 60  # Replacing WeightCarried = 0 by the non-null subset's median\n",
        "\n",
        "df[\"HandicapDistance\"] = df[\"HandicapDistance\"].replace({25:1, 50:2})"
      ],
      "metadata": {
        "id": "RM5hFERjA_Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## One-Hot Encoding categorical variables with 3+ levels\n",
        "\n",
        "# Initializing\n",
        "ohe = preprocessing.OneHotEncoder(drop=None, handle_unknown='error')\n",
        "\n",
        "# List of categorical variables with 3+ categories\n",
        "categorical_cols = [\"RaceGroup\",\"SexRestriction\",\"Surface\",\"Season\",\"HandicapType\",\"FrontShoes\",\"HindShoes\",\"StartingLine\"]\n",
        "\n",
        "for col in categorical_cols:\n",
        "  df[col] = df[col].apply(lambda x: str(col) + \"_\" + str(x))\n",
        "  transformed = ohe.fit_transform(df[[col]])\n",
        "  df[ohe.categories_[0]] = transformed.toarray().astype(int)"
      ],
      "metadata": {
        "id": "25z-Gx6SRFNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standardizing numerical race variables"
      ],
      "metadata": {
        "id": "9QfLjLDPl2pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_standardize_cols = [\"RacePrizemoney\",\"Distance\"]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df[to_standardize_cols])\n",
        "df.update(X_scaled)"
      ],
      "metadata": {
        "id": "rSU_8yyyl26_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaling variables at the RaceID level"
      ],
      "metadata": {
        "id": "3raej91brI5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_scale_cols = [\"Age_Prize_Interaction\",\"RestPeriod\",\"horse_Nb_Participations\",\"horse_NbWins\",\"horse_nb_timesplaced\",\"horse_totalprizemoney\",\"horse_CumulScore\",\n",
        "                 \"jockey_Nb_Participations\",\"jockey_NbWins\",\"jockey_nb_timesplaced\",\"jockey_totalprizemoney\",\"jockey_CumulScore\",\"trainer_Nb_Participations\",\"trainer_NbWins\",\n",
        "                 \"trainer_nb_timesplaced\",\"trainer_totalprizemoney\",\"trainer_CumulScore\",\"Saddlecloth\",\"WeightCarried\",\"Age_Prize_Interaction\", #\"BeatenMargin_norm_scaled\",\n",
        "                 ]\n",
        "\n",
        "for col in to_scale_cols:\n",
        "  df['Min_Score'] = df.groupby('RaceID')[col].transform('min')\n",
        "  df['Max_Score'] = df.groupby('RaceID')[col].transform('max')\n",
        "  df[col] = (df[col] - df['Min_Score']) / (df['Max_Score'] - df['Min_Score'])\n",
        "  df = df.drop(columns=[\"Min_Score\",\"Max_Score\"])"
      ],
      "metadata": {
        "id": "MDyhc5azq9Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imputation for missing values in engineered features"
      ],
      "metadata": {
        "id": "ClSucYMordlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing NaNs with 0.5\n",
        "nan_cols = [\"horse_NbWins\",\"horse_winrate\",\"horse_nb_timesplaced\",\"horse_totalprizemoney\",\"horse_AvgScore\",\"horse_AvgScore_Last5\",\"horse_CumulScore\",\"trainer_NbWins\",\n",
        "            \"trainer_winrate\",\"trainer_nb_timesplaced\",\"trainer_totalprizemoney\",\"trainer_AvgScore\",\"trainer_AvgScore_Last5\",\"trainer_CumulScore\",\"jockey_NbWins\",\"jockey_winrate\",\n",
        "            \"jockey_nb_timesplaced\",\"jockey_totalprizemoney\",\"jockey_AvgScore\",\"jockey_AvgScore_Last5\",\"jockey_CumulScore\",\"Age_Prize_Interaction\",\"horse_Nb_Participations\",\n",
        "            \"horse_past_perf_score_scaled\",\"horse_AvgScore_Last5_scaled\",\"jockey_AvgScore_scaled\",\"trainer_AvgScore_scaled\",\"CombinedPerformance_avgscore\"\n",
        "            ]\n",
        "\n",
        "for col in nan_cols:\n",
        "  df[col] = df[col].fillna(0.5) # Imputing with the middle value for neutrality"
      ],
      "metadata": {
        "id": "yErZg3a6rg1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For horses' first races, setting their RestPeriod with the sample's 75th percentile value\n",
        "df[\"RestPeriod\"] = df[\"RestPeriod\"].fillna(27)"
      ],
      "metadata": {
        "id": "QWIR7L14sHFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (OPTIONAL) Exporting the preprocessed dataframe"
      ],
      "metadata": {
        "id": "deBESccxmM1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping unprocessed columns\n",
        "df = df.drop(columns=[\"HorseAge\",\"Gender\",\"DamID\",\"SireID\",\"FoalingCountry\",\"FoalingDate\",\"FrontShoes\",\"HindShoes\",\"RaceGroup\",\"RacingSubType\",\"ClassRestriction\",\n",
        "                      \"min_age\",\"max_age\",\"SexRestriction\",\"TrackID\",\"Surface\",\"Season\",\"StartType\",\"StartingLine\",\"Barrier\",\"HandicapType\",\"FinishPosition_2\",\"RaceOverallTime\"\n",
        "                      ])"
      ],
      "metadata": {
        "id": "7KACzSsg67y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_parquet(\"preprocessed_df.parquet\", index=False)"
      ],
      "metadata": {
        "id": "VVw5r4aulqU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Feature Selection"
      ],
      "metadata": {
        "id": "qjTzwHMamZRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of features\n",
        "features = [\n",
        "    'RaceID','TrainerID','JockeyID','HorseID','RaceStartTime','FinishPosition','FinishPosition_3','WIN', 'Set',## are dropped after the train-test split\n",
        "    # Race variables\n",
        "    'RacePrizemoney','Nb_Participants','Distance','WetnessScale','Saddlecloth','WeightCarried','HandicapDistance','Gender_is_male','RacingType_mounted','StartType_volte',\n",
        "    'RaceGroup_G1','RaceGroup_G2','RaceGroup_G3','RaceGroup_Other',\n",
        "    'SexRestriction_Colts&Geldings','SexRestriction_Filly','SexRestriction_Mare','SexRestriction_None',\n",
        "    'Surface_C','Surface_S','Surface_T',\n",
        "    'Season_Fall','Season_Spring','Season_Summer','Season_Winter',\n",
        "    'HandicapType_Cwt','HandicapType_Hcp','HandicapType_SW','HandicapType_None',\n",
        "    'FrontShoes_0','FrontShoes_1','FrontShoes_2','FrontShoes_3',\n",
        "    'HindShoes_0','HindShoes_1','HindShoes_2','HindShoes_3',\n",
        "    'StartingLine_1.0','StartingLine_2.0','StartingLine_nan',\n",
        "    # Engineered features\n",
        "    'Relative_age','Age_Prize_Interaction','RestPeriod','horse_Nb_Participations','horse_NbWins','horse_winrate','horse_nb_timesplaced','horse_totalprizemoney',\n",
        "    'horse_AvgScore_Last5','horse_past_perf_score_scaled','horse_AvgScore_Last5_scaled','jockey_Nb_Participations','jockey_NbWins','jockey_winrate','jockey_nb_timesplaced',\n",
        "    'jockey_totalprizemoney','jockey_AvgScore_Last5','jockey_AvgScore_scaled','trainer_Nb_Participations','trainer_NbWins','trainer_winrate','trainer_nb_timesplaced',\n",
        "    'trainer_totalprizemoney','trainer_AvgScore_Last5','trainer_AvgScore_scaled',\"Dam_Past_Performance\",\"Sire_Past_Performance\",\"CombinedPerformance_winrate\",\n",
        "    \"CombinedPerformance_avg5score\",\"horse_consistency\",\"race_prizemoney_score\",\"composite_past_perf_score\",\"field_strength_scaled\",\"is_preferred_surface\"\n",
        "]\n",
        "\n",
        "df = df[features]"
      ],
      "metadata": {
        "id": "-whSXNXHmgBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Train-Test Split"
      ],
      "metadata": {
        "id": "cJGW7dnPmgUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traindf = df.loc[df[\"Set\"]==\"train\"]\n",
        "testdf = df.loc[df[\"Set\"]==\"test\"]"
      ],
      "metadata": {
        "id": "L2VyaofEmnBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TRAIN SET\n",
        "# Dropping the target variable and ID columns\n",
        "X_train = traindf.drop(columns=[\"WIN\",\"RaceID\",\"HorseID\",\"JockeyID\",\"TrainerID\",\"RaceStartTime\",\"FinishPosition\",\"FinishPosition_3\",\"Set\"])\n",
        "\n",
        "# Target variable\n",
        "y_train = traindf['WIN']\n",
        "\n",
        "\n",
        "## TEST SET\n",
        "# Dropping the target variable and ID columns\n",
        "X_test = testdf.drop(columns=[\"WIN\",\"RaceID\",\"HorseID\",\"JockeyID\",\"TrainerID\",\"RaceStartTime\",\"FinishPosition\",\"FinishPosition_3\",\"Set\"])\n",
        "\n",
        "# Target variable\n",
        "y_test = testdf['WIN']"
      ],
      "metadata": {
        "id": "4TyW4FWkqJ2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of winners (class 1) in the train set: \", traindf.WIN.sum())\n",
        "print(\"Total number of rows in the train set: \",traindf.shape[0])\n",
        "\n",
        "print(\"\\nNumber of winners (class 1) in the test set: \",testdf.WIN.sum())\n",
        "print(\"Total number of rows in the test set: \",testdf.shape[0])"
      ],
      "metadata": {
        "id": "BpFaPHaAqeWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Model training"
      ],
      "metadata": {
        "id": "C_Q6nYfZmVAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost model parameters\n",
        "xgb = XGBClassifier(random_state=0, scale_pos_weight=1, min_child_weight=1, max_depth=7, learning_rate=0.1, gamma=0.1, colsample_bytree=0.9, subsample=0.7, eval_metric=\"logloss\")\n",
        "\n",
        "# Train on training set\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on testing set\n",
        "y_pred = xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "w3KWuWtummk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Post-processing, performance metrics & feature importance"
      ],
      "metadata": {
        "id": "YU_KxSgOmnaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Obtaining probabilities\n",
        "testset_probs = xgb.predict_proba(X_test).tolist()\n",
        "probs = pd.DataFrame(testset_probs)\n",
        "probs.columns = [\"Predicted_probability_0\",\"Predicted_probability_1\"]\n",
        "\n",
        "# Merging with test set to compare the predictions with the actual results\n",
        "testdf_results = testdf[[\"RaceID\",\"HorseID\",\"WIN\"]].reset_index().drop(columns=\"index\")\n",
        "testdf_results = testdf_results.join(probs, on=testdf_results.index)\n",
        "\n",
        "# Scaling probabilities at RaceID level\n",
        "testdf_results['winprobability'] = testdf_results.groupby('RaceID')['Predicted_probability_1'].transform(lambda x: x / x.sum())"
      ],
      "metadata": {
        "id": "rVoKx3Omm1EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Class label predictions\n",
        "\n",
        "# Listing the horses with the highest Scaled Probability for each RaceID\n",
        "predicted_winners = testdf_results.sort_values(by=['RaceID', 'winprobability'], ascending=[True, False]).drop_duplicates(subset='RaceID', keep='first')[['RaceID', 'HorseID']]\n",
        "raceids = predicted_winners.RaceID.tolist()\n",
        "horseids = predicted_winners.HorseID.tolist()\n",
        "len(horseids), len(raceids)\n",
        "\n",
        "# Creating a new variable WIN_pred indicating the predicted winner for each RaceID\n",
        "testdf_results['WIN_pred'] = False\n",
        "\n",
        "for horse, race in zip(horseids, raceids):\n",
        "  mask = (testdf_results['RaceID'] == race) & (testdf_results['HorseID'] == horse)\n",
        "  testdf_results.loc[mask, 'WIN_pred'] = True\n",
        "\n",
        "testdf_results[\"WIN_pred\"] = testdf_results[\"WIN_pred\"].astype(int)"
      ],
      "metadata": {
        "id": "rGVBktLivXNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Performance metrics\n",
        "accuracy = accuracy_score(testdf_results[\"WIN\"], testdf_results[\"WIN_pred\"])\n",
        "print(\"Accuracy:\", accuracy.round(3))\n",
        "precision = precision_score(testdf_results[\"WIN\"], testdf_results[\"WIN_pred\"])\n",
        "print(\"Precision:\", precision.round(3))\n",
        "recall = recall_score(testdf_results[\"WIN\"], testdf_results[\"WIN_pred\"])\n",
        "print(\"Recall:\", recall.round(3))\n",
        "\n",
        "# Log loss score\n",
        "def logloss(true_labels, predicted_probs, eps=1e-15):\n",
        "  p = np.clip(predicted_probs, eps, 1 - eps)\n",
        "  loss = -np.log(p) * true_labels - np.log(1 - p) * (1 - true_labels)\n",
        "  return np.mean(loss)\n",
        "\n",
        "logloss_score = logloss(true_labels=testdf_results[\"WIN\"], predicted_probs=testdf_results[\"winprobability\"])\n",
        "print(\"Log loss score: \",logloss_score.round(4))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(testdf_results[\"WIN\"], testdf_results[\"WIN_pred\"])\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm).plot(colorbar=False, cmap='Blues');"
      ],
      "metadata": {
        "id": "89mP0_9RvkeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance\n",
        "feature_importances = pd.Series(xgb.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "feature_importances = feature_importances.to_frame().reset_index().rename(columns={\"index\":\"feature\",0:\"importance\"})\n",
        "print(feature_importances.head(5))\n",
        "\n",
        "fig = px.histogram(feature_importances, x=\"feature\", y=\"importance\")\n",
        "fig.update_xaxes(tickangle=45)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "NMhznog6wQfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Winprobability output for test set"
      ],
      "metadata": {
        "id": "27V492TBm1j3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testdf_results = testdf_results.rename(columns = {\"WIN_pred\":\"win_classprediction\", \"WIN\":\"win_groundtruth\"})\n",
        "output = testdf_results[['RaceID','HorseID','winprobability','win_classprediction','win_groundtruth']]\n",
        "print(output)\n",
        "output.to_parquet('newdata_predictions.parquet',index=False)"
      ],
      "metadata": {
        "id": "n8jZy_G4m9GM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}